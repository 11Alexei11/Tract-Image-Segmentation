{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "201b4c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda connected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-08 23:18:06.891708: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-08 23:18:06.892102: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-08 23:18:06.892397: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-08 23:18:06.892726: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-08 23:18:06.893004: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-08 23:18:06.893241: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /device:GPU:0 with 2642 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sys import getsizeof\n",
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "\n",
    "if tf.test.is_gpu_available():\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "    print('cuda connected')\n",
    "\n",
    "import segmentation_models as sm\n",
    "sm.set_framework('tf.keras')\n",
    "sm.framework()\n",
    "\n",
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c14f6e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle_decode(mask_rle, shape):\n",
    "    '''\n",
    "    mask_rle: run-length as string formated (start length)\n",
    "    shape: (height,width) of array to return \n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "\n",
    "    '''\n",
    "    s = np.asarray(mask_rle.split(), dtype=int)\n",
    "    starts = s[0::2] - 1\n",
    "    lengths = s[1::2]\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape)  # Needed to align to RLE direction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e76401f",
   "metadata": {},
   "source": [
    "# TIS inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e2943c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_clip_0_1(x, **kwargs):\n",
    "    return x.round().clip(0, 1)\n",
    "\n",
    "# define heavy augmentations\n",
    "def get_training_augmentation():\n",
    "    train_transform = [\n",
    "\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "\n",
    "        A.ShiftScaleRotate(scale_limit=0.5, rotate_limit=0, shift_limit=0.1, p=1, border_mode=0),\n",
    "\n",
    "        A.PadIfNeeded(min_height=320, min_width=320, always_apply=True, border_mode=0),\n",
    "        A.RandomCrop(height=320, width=320, always_apply=True),\n",
    "\n",
    "        A.IAAPerspective(p=0.5),\n",
    "\n",
    "        A.OneOf(\n",
    "            [\n",
    "                A.CLAHE(p=1),\n",
    "                A.RandomBrightness(p=1),\n",
    "                A.RandomGamma(p=1),\n",
    "            ],\n",
    "            p=0.9,\n",
    "        ),\n",
    "\n",
    "        A.OneOf(\n",
    "            [\n",
    "                A.IAASharpen(p=1),\n",
    "                A.Blur(blur_limit=3, p=1),\n",
    "                A.MotionBlur(blur_limit=3, p=1),\n",
    "            ],\n",
    "            p=0.9,\n",
    "        ),\n",
    "\n",
    "        A.OneOf(\n",
    "            [\n",
    "                A.RandomContrast(p=1),\n",
    "                A.HueSaturationValue(p=1),\n",
    "            ],\n",
    "            p=0.9,\n",
    "        ),\n",
    "        A.Lambda(mask=round_clip_0_1)\n",
    "    ]\n",
    "    return A.Compose(train_transform)\n",
    "\n",
    "\n",
    "def get_validation_augmentation():\n",
    "    \"\"\"Add paddings to make image shape divisible by 32\"\"\"\n",
    "    test_transform = [\n",
    "        A.PadIfNeeded(384, 480)\n",
    "    ]\n",
    "    return A.Compose(test_transform)\n",
    "\n",
    "def get_preprocessing(preprocessing_fn):\n",
    "    \"\"\"Construct preprocessing transform\n",
    "    \n",
    "    Args:\n",
    "        preprocessing_fn (callbale): data normalization function \n",
    "            (can be specific for each pretrained neural network)\n",
    "    Return:\n",
    "        transform: albumentations.Compose\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    _transform = [\n",
    "        A.Lambda(image=preprocessing_fn),\n",
    "    ]\n",
    "    return A.Compose(_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "709f1e01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ares/work/TIS'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DIRECTORY = os.getcwd()\n",
    "DIRECTORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba16bd98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "large_bowel    14085\n",
       "small_bowel    11201\n",
       "stomach         8627\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('/home/ares/work/TIS/train.csv')\n",
    "data = data[data['segmentation'].isna()==False]\n",
    "data['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f557967c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_paths_to_imgs = []\n",
    "for id in data['id']:\n",
    "    splitted_id = id.split('_')\n",
    "    local_path = DIRECTORY\n",
    "    for i, part in enumerate(splitted_id):\n",
    "        if part == 'slice':\n",
    "            local_path = os.path.join(local_path, part + f\"_{splitted_id[-1]}\")\n",
    "            break\n",
    "        elif \"day\" in part:\n",
    "            local_path = os.path.join(local_path, f\"{local_path.split('/')[-1]}_\" + part)\n",
    "            local_path = os.path.join(local_path, 'scans')\n",
    "        else:\n",
    "            local_path = os.path.join(local_path, \"train\", part)\n",
    "    all_files = glob(local_path + \"_*\")\n",
    "    all_paths_to_imgs.append(all_files)\n",
    "all_paths_to_imgs = np.array(all_paths_to_imgs).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45630ad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "      <th>segmentation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/ares/work/TIS/train/case123/case123_day2...</td>\n",
       "      <td>stomach</td>\n",
       "      <td>28094 3 28358 7 28623 9 28889 9 29155 9 29421 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/ares/work/TIS/train/case123/case123_day2...</td>\n",
       "      <td>stomach</td>\n",
       "      <td>27561 8 27825 11 28090 13 28355 14 28620 15 28...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/ares/work/TIS/train/case123/case123_day2...</td>\n",
       "      <td>stomach</td>\n",
       "      <td>15323 4 15587 8 15852 10 16117 11 16383 12 166...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/ares/work/TIS/train/case123/case123_day2...</td>\n",
       "      <td>stomach</td>\n",
       "      <td>14792 5 15056 9 15321 11 15587 11 15852 13 161...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/ares/work/TIS/train/case123/case123_day2...</td>\n",
       "      <td>stomach</td>\n",
       "      <td>14526 6 14789 12 15054 14 15319 16 15584 17 15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33908</th>\n",
       "      <td>/home/ares/work/TIS/train/case30/case30_day0/s...</td>\n",
       "      <td>small_bowel</td>\n",
       "      <td>22540 1 22804 5 23069 7 23334 10 23600 11 2386...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33909</th>\n",
       "      <td>/home/ares/work/TIS/train/case30/case30_day0/s...</td>\n",
       "      <td>large_bowel</td>\n",
       "      <td>18746 7 19009 23 19038 7 19273 44 19537 49 198...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33910</th>\n",
       "      <td>/home/ares/work/TIS/train/case30/case30_day0/s...</td>\n",
       "      <td>small_bowel</td>\n",
       "      <td>23079 1 23343 6 23608 9 23874 11 24139 13 2440...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33911</th>\n",
       "      <td>/home/ares/work/TIS/train/case30/case30_day0/s...</td>\n",
       "      <td>large_bowel</td>\n",
       "      <td>18746 2 19010 8 19040 3 19274 25 19302 12 1953...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33912</th>\n",
       "      <td>/home/ares/work/TIS/train/case30/case30_day0/s...</td>\n",
       "      <td>small_bowel</td>\n",
       "      <td>21457 6 21722 10 21987 15 22252 18 22517 21 22...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33913 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      id        class  \\\n",
       "0      /home/ares/work/TIS/train/case123/case123_day2...      stomach   \n",
       "1      /home/ares/work/TIS/train/case123/case123_day2...      stomach   \n",
       "2      /home/ares/work/TIS/train/case123/case123_day2...      stomach   \n",
       "3      /home/ares/work/TIS/train/case123/case123_day2...      stomach   \n",
       "4      /home/ares/work/TIS/train/case123/case123_day2...      stomach   \n",
       "...                                                  ...          ...   \n",
       "33908  /home/ares/work/TIS/train/case30/case30_day0/s...  small_bowel   \n",
       "33909  /home/ares/work/TIS/train/case30/case30_day0/s...  large_bowel   \n",
       "33910  /home/ares/work/TIS/train/case30/case30_day0/s...  small_bowel   \n",
       "33911  /home/ares/work/TIS/train/case30/case30_day0/s...  large_bowel   \n",
       "33912  /home/ares/work/TIS/train/case30/case30_day0/s...  small_bowel   \n",
       "\n",
       "                                            segmentation  \n",
       "0      28094 3 28358 7 28623 9 28889 9 29155 9 29421 ...  \n",
       "1      27561 8 27825 11 28090 13 28355 14 28620 15 28...  \n",
       "2      15323 4 15587 8 15852 10 16117 11 16383 12 166...  \n",
       "3      14792 5 15056 9 15321 11 15587 11 15852 13 161...  \n",
       "4      14526 6 14789 12 15054 14 15319 16 15584 17 15...  \n",
       "...                                                  ...  \n",
       "33908  22540 1 22804 5 23069 7 23334 10 23600 11 2386...  \n",
       "33909  18746 7 19009 23 19038 7 19273 44 19537 49 198...  \n",
       "33910  23079 1 23343 6 23608 9 23874 11 24139 13 2440...  \n",
       "33911  18746 2 19010 8 19040 3 19274 25 19302 12 1953...  \n",
       "33912  21457 6 21722 10 21987 15 22252 18 22517 21 22...  \n",
       "\n",
       "[33913 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refreshed_data = data.copy()\n",
    "refreshed_data['id'] = all_paths_to_imgs\n",
    "refreshed_data.index = range(refreshed_data.shape[0])\n",
    "refreshed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "173079ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for data visualization\n",
    "def visualize(**images):\n",
    "    \"\"\"PLot images in one row.\"\"\"\n",
    "    n = len(images)\n",
    "    plt.figure(figsize=(16, 5))\n",
    "    for i, (name, image) in enumerate(images.items()):\n",
    "        plt.subplot(1, n, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(' '.join(name.split('_')).title())\n",
    "        plt.imshow(image)\n",
    "    plt.show()\n",
    "    \n",
    "# helper function for data visualization    \n",
    "def denormalize(x):\n",
    "    \"\"\"Scale image to range 0..1 for correct plot\"\"\"\n",
    "    x_max = np.percentile(x, 98)\n",
    "    x_min = np.percentile(x, 2)    \n",
    "    x = (x - x_min) / (x_max - x_min)\n",
    "    x = x.clip(0, 1)\n",
    "    return x\n",
    "\n",
    "\n",
    "# classes for data loading and preprocessing\n",
    "class Dataset:\n",
    "    \"\"\"CamVid Dataset. Read images, apply augmentation and preprocessing transformations.\n",
    "    \n",
    "    Args:\n",
    "        images_dir (str): path to images folder\n",
    "        masks_dir (str): path to segmentation masks folder\n",
    "        class_values (list): values of classes to extract from segmentation mask\n",
    "        augmentation (albumentations.Compose): data transfromation pipeline \n",
    "            (e.g. flip, scale, etc.)\n",
    "        preprocessing (albumentations.Compose): data preprocessing \n",
    "            (e.g. noralization, shape manipulation, etc.)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "            self,\n",
    "            data: pd.DataFrame,\n",
    "            augmentation=None,\n",
    "            preprocessing=None,\n",
    "    ):\n",
    "        self.images_fps = data['id'].values\n",
    "        self.masks_rle_encode = data['segmentation'].values\n",
    "\n",
    "        # convert str names to class values on masks\n",
    "        \n",
    "        self.augmentation = augmentation\n",
    "        self.preprocessing = preprocessing\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        \n",
    "        # read data\n",
    "        image = cv2.imread(self.images_fps[i])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.uint8)\n",
    "\n",
    "        mask = rle_decode(self.masks_rle_encode[i], image.shape[:2]).astype(np.float32)\n",
    "        mask = np.expand_dims(mask, axis=2)\n",
    "        \n",
    "        # add background if mask is not binary\n",
    "        # if mask.shape[-1] != 1:\n",
    "        #     background = 1 - mask.sum(axis=-1, keepdims=True)\n",
    "        #     mask = np.concatenate((mask, background), axis=-1)\n",
    "        \n",
    "        \n",
    "        # apply augmentations\n",
    "        if self.augmentation:\n",
    "            sample = self.augmentation(image=image, mask=mask)\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "        \n",
    "        # apply preprocessing\n",
    "        if self.preprocessing:\n",
    "            sample = self.preprocessing(image=image, mask=mask)\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "            \n",
    "        return image, mask\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.images_fps.shape[0]\n",
    "    \n",
    "    \n",
    "class Dataloader(tf.keras.utils.Sequence):\n",
    "    \"\"\"Load data from dataset and form batches\n",
    "    \n",
    "    Args:\n",
    "        dataset: instance of Dataset class for image loading and preprocessing.\n",
    "        batch_size: Integet number of images in batch.\n",
    "        shuffle: Boolean, if `True` shuffle image indexes each epoch.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, dataset, batch_size=1, shuffle=False):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indexes = np.arange(len(self.dataset))\n",
    "\n",
    "        self.on_epoch_end()\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        \n",
    "        # collect batch data\n",
    "        start = i * self.batch_size\n",
    "        stop = (i + 1) * self.batch_size\n",
    "        data = []\n",
    "        for j in range(start, stop):\n",
    "            data.append(self.dataset[j])\n",
    "        # transpose list of lists\n",
    "        batch = [np.stack(samples, axis=0) for samples in zip(*data)]\n",
    "        \n",
    "        return batch\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"Denotes the number of batches per epoch\"\"\"\n",
    "        return len(self.indexes) // self.batch_size\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"Callback function to shuffle indexes each epoch\"\"\"\n",
    "        if self.shuffle:\n",
    "            self.indexes = np.random.permutation(self.indexes)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a17967f",
   "metadata": {},
   "source": [
    "## CREATE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7744e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "BACKBONE = 'efficientnetb0'\n",
    "BATCH_SIZE = 5\n",
    "LR = 0.01\n",
    "EPOCHS = 100\n",
    "MODEL_NAME = \"unet\"\n",
    "PATH_TO_MODEL = f\"./models/{MODEL_NAME}.h5\"\n",
    "LOAD_MODEL = False\n",
    "\n",
    "base_model_params = {\n",
    "    \"backbone\": BACKBONE,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"epochs\": EPOCHS\n",
    "}\n",
    "preprocess_input = sm.get_preprocessing(BACKBONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ada1b8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col_name = \"class\"\n",
    "train_data, val_data, y_train, y_val = train_test_split(refreshed_data.drop(target_col_name, axis=1), refreshed_data[target_col_name], \\\n",
    "    test_size=0.2, stratify=refreshed_data[target_col_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35a1919d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(\n",
    "    data=train_data.join(y_train), \n",
    "    augmentation=get_training_augmentation(),\n",
    "    preprocessing=get_preprocessing(preprocess_input))\n",
    "\n",
    "val_dataset = Dataset(\n",
    "    val_data.join(y_val),\n",
    "    augmentation=get_validation_augmentation(),\n",
    "    preprocessing=get_preprocessing(preprocess_input)\n",
    "    )\n",
    "\n",
    "train_data_loader = Dataloader(train_dataset, batch_size=BATCH_SIZE)\n",
    "val_data_loader = Dataloader(val_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d18dc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define network parameters\n",
    "n_classes = 3  # case for binary and multiclass segmentation\n",
    "activation = 'sigmoid' if n_classes == 1 else 'softmax'\n",
    "\n",
    "#create model\n",
    "model = sm.Unet(BACKBONE, classes=n_classes, activation=activation, encoder_freeze=True)\n",
    "MODEL_NAME = \"Unet\"\n",
    "# model = sm.FPN(BACKBONE, classes=n_classes, activation=activation)\n",
    "\n",
    "if LOAD_MODEL:\n",
    "    model.load_weights(PATH_TO_MODEL)\n",
    "    print('weights loaded')\n",
    "    base_model_params['model-name'] = MODEL_NAME\n",
    "    base_model_params['backbone-name'] = BACKBONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5195235e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define optomizer\n",
    "\n",
    "optim = tf.keras.optimizers.Adam(LR)\n",
    "base_model_params['optimizer'] = optim.get_config()['name']\n",
    "\n",
    "# Segmentation models losses can be combined together by '+' and scaled by integer or float factor\n",
    "dice_coef, focal_coef = 0.6, 0.4\n",
    "dice_loss = sm.losses.DiceLoss()\n",
    "focal_loss = sm.losses.BinaryFocalLoss() if n_classes == 1 else sm.losses.CategoricalFocalLoss()\n",
    "total_loss = dice_loss*dice_coef + (1 * focal_loss)*focal_coef\n",
    "\n",
    "base_model_params['dice loss coef'] = dice_coef\n",
    "base_model_params['focal loss coef'] = focal_coef\n",
    "\n",
    "# actulally total_loss can be imported directly from library, above example just show you how to manipulate with losses\n",
    "# total_loss = sm.losses.binary_focal_dice_loss # or sm.losses.categorical_focal_dice_loss \n",
    "\n",
    "metrics = [sm.metrics.IOUScore(threshold=0.5), sm.metrics.FScore(threshold=0.5)]\n",
    "\n",
    "# learning rate schedule\n",
    "def step_decay(epoch):\n",
    "\tinitial_lrate = 0.001\n",
    "\tdrop = 0.9\n",
    "\tepochs_drop = 10.0\n",
    "\tlrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "\treturn lrate\n",
    "\n",
    "# compile keras model with defined optimozer, loss and metrics\n",
    "model.compile(optim, total_loss, metrics)\n",
    "\n",
    "callbacks = [\n",
    "\ttf.keras.callbacks.ModelCheckpoint(PATH_TO_MODEL, save_weights_only=True, save_best_only=True, mode='min'),\n",
    "\ttf.keras.callbacks.CSVLogger('./logging/log.csv'),\n",
    "\ttf.keras.callbacks.LearningRateScheduler(step_decay)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0599d6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-08 23:19:17.780391: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8400\n",
      "2022-10-08 23:19:20.464930: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.08GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-10-08 23:19:20.465700: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.08GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-10-08 23:19:20.601344: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.09GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-10-08 23:19:20.601375: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.09GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-10-08 23:19:20.778837: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.34GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-10-08 23:19:20.778873: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.34GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-10-08 23:19:20.976744: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.93GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-10-08 23:19:20.976781: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.93GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-10-08 23:19:22.323023: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.61GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-10-08 23:19:22.323057: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.61GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5426/5426 [==============================] - 1419s 259ms/step - loss: 0.5021 - iou_score: 0.1047 - f1-score: 0.1762 - val_loss: 0.4859 - val_iou_score: 0.1223 - val_f1-score: 0.1990 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "5426/5426 [==============================] - 1404s 259ms/step - loss: 0.4910 - iou_score: 0.1172 - f1-score: 0.1937 - val_loss: 0.4799 - val_iou_score: 0.1310 - val_f1-score: 0.2091 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "5426/5426 [==============================] - 1405s 259ms/step - loss: 0.4867 - iou_score: 0.1221 - f1-score: 0.2003 - val_loss: 0.4713 - val_iou_score: 0.1390 - val_f1-score: 0.2216 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "5426/5426 [==============================] - 1407s 259ms/step - loss: 0.4854 - iou_score: 0.1236 - f1-score: 0.2024 - val_loss: 0.4745 - val_iou_score: 0.1357 - val_f1-score: 0.2171 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "5426/5426 [==============================] - 1403s 259ms/step - loss: 0.4840 - iou_score: 0.1252 - f1-score: 0.2044 - val_loss: 0.4684 - val_iou_score: 0.1421 - val_f1-score: 0.2266 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "5426/5426 [==============================] - 1602s 295ms/step - loss: 0.4828 - iou_score: 0.1266 - f1-score: 0.2064 - val_loss: 0.4712 - val_iou_score: 0.1398 - val_f1-score: 0.2226 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "1315/5426 [======>.......................] - ETA: 30:12 - loss: 0.4832 - iou_score: 0.1265 - f1-score: 0.2056"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/ares/work/TIS/full-pipeline.ipynb Cell 16\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ares/work/TIS/full-pipeline.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# # train model\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/ares/work/TIS/full-pipeline.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit_generator(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ares/work/TIS/full-pipeline.ipynb#X21sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     train_data_loader,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ares/work/TIS/full-pipeline.ipynb#X21sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(train_data_loader),\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ares/work/TIS/full-pipeline.ipynb#X21sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49mEPOCHS,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ares/work/TIS/full-pipeline.ipynb#X21sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ares/work/TIS/full-pipeline.ipynb#X21sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     validation_data\u001b[39m=\u001b[39;49mval_data_loader,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ares/work/TIS/full-pipeline.ipynb#X21sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     validation_steps\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(val_data_loader),\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ares/work/TIS/full-pipeline.ipynb#X21sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/training.py:2209\u001b[0m, in \u001b[0;36mModel.fit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2198\u001b[0m \u001b[39m\"\"\"Fits the model on data yielded batch-by-batch by a Python generator.\u001b[39;00m\n\u001b[1;32m   2199\u001b[0m \n\u001b[1;32m   2200\u001b[0m \u001b[39mDEPRECATED:\u001b[39;00m\n\u001b[1;32m   2201\u001b[0m \u001b[39m  `Model.fit` now supports generators, so there is no longer any need to use\u001b[39;00m\n\u001b[1;32m   2202\u001b[0m \u001b[39m  this endpoint.\u001b[39;00m\n\u001b[1;32m   2203\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2204\u001b[0m warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   2205\u001b[0m     \u001b[39m'\u001b[39m\u001b[39m`Model.fit_generator` is deprecated and \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   2206\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mwill be removed in a future version. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   2207\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mPlease use `Model.fit`, which supports generators.\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   2208\u001b[0m     stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m-> 2209\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m   2210\u001b[0m     generator,\n\u001b[1;32m   2211\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[1;32m   2212\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[1;32m   2213\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m   2214\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m   2215\u001b[0m     validation_data\u001b[39m=\u001b[39;49mvalidation_data,\n\u001b[1;32m   2216\u001b[0m     validation_steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[1;32m   2217\u001b[0m     validation_freq\u001b[39m=\u001b[39;49mvalidation_freq,\n\u001b[1;32m   2218\u001b[0m     class_weight\u001b[39m=\u001b[39;49mclass_weight,\n\u001b[1;32m   2219\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[1;32m   2220\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[1;32m   2221\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[1;32m   2222\u001b[0m     shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[1;32m   2223\u001b[0m     initial_epoch\u001b[39m=\u001b[39;49minitial_epoch)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1377\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1378\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   1379\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   1380\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[1;32m   1381\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m   1382\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m   1383\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1384\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1385\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1386\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2953\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2954\u001b[0m   (graph_function,\n\u001b[1;32m   2955\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2956\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2957\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1849\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1850\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1851\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1852\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1853\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1854\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1855\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m     args,\n\u001b[1;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1858\u001b[0m     executing_eagerly)\n\u001b[1;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# # train model\n",
    "history = model.fit_generator(\n",
    "    train_data_loader,\n",
    "    steps_per_epoch=len(train_data_loader),\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=val_data_loader,\n",
    "    validation_steps=len(val_data_loader),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21ba7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_params['loss'] = history.history['loss']\n",
    "with mlflow.start_run():\n",
    "    # mlflow.create_experiment('fit-segmentation-model', artifact_location='./models')\n",
    "    mlflow.log_params(base_model_params)\n",
    "    mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc6275fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from  mlflow.tracking import MlflowClient\n",
    "client = MlflowClient()\n",
    "experiments = client.list_experiments() # returns a list of mlflow.entities.Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6af9ad5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///home/ares/work/TIS/mlruns/0', experiment_id='0', lifecycle_stage='active', name='Default', tags={}>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiments[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac3ef5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = client.get_run('0207c13cc40a4c2e99fa251bd6166f82')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d910ca17",
   "metadata": {},
   "source": [
    "## Famous models preporation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e78ed3",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
