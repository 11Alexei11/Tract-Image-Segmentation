{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "201b4c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_4220/2061984816.py:21: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "cuda connected\n",
      "Segmentation Models: using `keras` framework.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-02 14:00:13.705320: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-02 14:00:14.678412: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-02 14:00:14.737661: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-02 14:00:14.737949: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-02 14:00:15.580729: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-02 14:00:15.581077: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-02 14:00:15.581331: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-02 14:00:15.582386: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /device:GPU:0 with 2642 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sys import getsizeof\n",
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "\n",
    "if tf.test.is_gpu_available():\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "    print('cuda connected')\n",
    "\n",
    "import segmentation_models as sm\n",
    "sm.set_framework('tf.keras')\n",
    "sm.framework()\n",
    "\n",
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c14f6e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle_decode(mask_rle, shape):\n",
    "    '''\n",
    "    mask_rle: run-length as string formated (start length)\n",
    "    shape: (height,width) of array to return \n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "\n",
    "    '''\n",
    "    s = np.asarray(mask_rle.split(), dtype=int)\n",
    "    starts = s[0::2] - 1\n",
    "    lengths = s[1::2]\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape)  # Needed to align to RLE direction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e76401f",
   "metadata": {},
   "source": [
    "# TIS inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e2943c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_clip_0_1(x, **kwargs):\n",
    "    return x.round().clip(0, 1)\n",
    "\n",
    "# define heavy augmentations\n",
    "def get_training_augmentation():\n",
    "    train_transform = [\n",
    "\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "\n",
    "        A.ShiftScaleRotate(scale_limit=0.5, rotate_limit=0, shift_limit=0.1, p=1, border_mode=0),\n",
    "\n",
    "        A.PadIfNeeded(min_height=320, min_width=320, always_apply=True, border_mode=0),\n",
    "        A.RandomCrop(height=320, width=320, always_apply=True),\n",
    "\n",
    "        A.IAAPerspective(p=0.5),\n",
    "\n",
    "        A.OneOf(\n",
    "            [\n",
    "                A.CLAHE(p=1),\n",
    "                A.RandomBrightness(p=1),\n",
    "                A.RandomGamma(p=1),\n",
    "            ],\n",
    "            p=0.9,\n",
    "        ),\n",
    "\n",
    "        A.OneOf(\n",
    "            [\n",
    "                A.IAASharpen(p=1),\n",
    "                A.Blur(blur_limit=3, p=1),\n",
    "                A.MotionBlur(blur_limit=3, p=1),\n",
    "            ],\n",
    "            p=0.9,\n",
    "        ),\n",
    "\n",
    "        A.OneOf(\n",
    "            [\n",
    "                A.RandomContrast(p=1),\n",
    "                A.HueSaturationValue(p=1),\n",
    "            ],\n",
    "            p=0.9,\n",
    "        ),\n",
    "        A.Lambda(mask=round_clip_0_1)\n",
    "    ]\n",
    "    return A.Compose(train_transform)\n",
    "\n",
    "\n",
    "def get_validation_augmentation():\n",
    "    \"\"\"Add paddings to make image shape divisible by 32\"\"\"\n",
    "    test_transform = [\n",
    "        A.PadIfNeeded(384, 480)\n",
    "    ]\n",
    "    return A.Compose(test_transform)\n",
    "\n",
    "def get_preprocessing(preprocessing_fn):\n",
    "    \"\"\"Construct preprocessing transform\n",
    "    \n",
    "    Args:\n",
    "        preprocessing_fn (callbale): data normalization function \n",
    "            (can be specific for each pretrained neural network)\n",
    "    Return:\n",
    "        transform: albumentations.Compose\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    _transform = [\n",
    "        A.Lambda(image=preprocessing_fn),\n",
    "    ]\n",
    "    return A.Compose(_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "709f1e01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ares/work/TIS'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DIRECTORY = os.getcwd()\n",
    "DIRECTORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba16bd98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "large_bowel    14085\n",
       "small_bowel    11201\n",
       "stomach         8627\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('/home/ares/work/TIS/train.csv')\n",
    "data = data[data['segmentation'].isna()==False]\n",
    "data['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f557967c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_paths_to_imgs = []\n",
    "for id in data['id']:\n",
    "    splitted_id = id.split('_')\n",
    "    local_path = DIRECTORY\n",
    "    for i, part in enumerate(splitted_id):\n",
    "        if part == 'slice':\n",
    "            local_path = os.path.join(local_path, part + f\"_{splitted_id[-1]}\")\n",
    "            break\n",
    "        elif \"day\" in part:\n",
    "            local_path = os.path.join(local_path, f\"{local_path.split('/')[-1]}_\" + part)\n",
    "            local_path = os.path.join(local_path, 'scans')\n",
    "        else:\n",
    "            local_path = os.path.join(local_path, \"train\", part)\n",
    "    all_files = glob(local_path + \"_*\")\n",
    "    all_paths_to_imgs.append(all_files)\n",
    "all_paths_to_imgs = np.array(all_paths_to_imgs).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45630ad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "      <th>segmentation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/ares/work/TIS/train/case123/case123_day2...</td>\n",
       "      <td>stomach</td>\n",
       "      <td>28094 3 28358 7 28623 9 28889 9 29155 9 29421 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/ares/work/TIS/train/case123/case123_day2...</td>\n",
       "      <td>stomach</td>\n",
       "      <td>27561 8 27825 11 28090 13 28355 14 28620 15 28...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/ares/work/TIS/train/case123/case123_day2...</td>\n",
       "      <td>stomach</td>\n",
       "      <td>15323 4 15587 8 15852 10 16117 11 16383 12 166...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/ares/work/TIS/train/case123/case123_day2...</td>\n",
       "      <td>stomach</td>\n",
       "      <td>14792 5 15056 9 15321 11 15587 11 15852 13 161...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/ares/work/TIS/train/case123/case123_day2...</td>\n",
       "      <td>stomach</td>\n",
       "      <td>14526 6 14789 12 15054 14 15319 16 15584 17 15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33908</th>\n",
       "      <td>/home/ares/work/TIS/train/case30/case30_day0/s...</td>\n",
       "      <td>small_bowel</td>\n",
       "      <td>22540 1 22804 5 23069 7 23334 10 23600 11 2386...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33909</th>\n",
       "      <td>/home/ares/work/TIS/train/case30/case30_day0/s...</td>\n",
       "      <td>large_bowel</td>\n",
       "      <td>18746 7 19009 23 19038 7 19273 44 19537 49 198...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33910</th>\n",
       "      <td>/home/ares/work/TIS/train/case30/case30_day0/s...</td>\n",
       "      <td>small_bowel</td>\n",
       "      <td>23079 1 23343 6 23608 9 23874 11 24139 13 2440...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33911</th>\n",
       "      <td>/home/ares/work/TIS/train/case30/case30_day0/s...</td>\n",
       "      <td>large_bowel</td>\n",
       "      <td>18746 2 19010 8 19040 3 19274 25 19302 12 1953...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33912</th>\n",
       "      <td>/home/ares/work/TIS/train/case30/case30_day0/s...</td>\n",
       "      <td>small_bowel</td>\n",
       "      <td>21457 6 21722 10 21987 15 22252 18 22517 21 22...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33913 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      id        class  \\\n",
       "0      /home/ares/work/TIS/train/case123/case123_day2...      stomach   \n",
       "1      /home/ares/work/TIS/train/case123/case123_day2...      stomach   \n",
       "2      /home/ares/work/TIS/train/case123/case123_day2...      stomach   \n",
       "3      /home/ares/work/TIS/train/case123/case123_day2...      stomach   \n",
       "4      /home/ares/work/TIS/train/case123/case123_day2...      stomach   \n",
       "...                                                  ...          ...   \n",
       "33908  /home/ares/work/TIS/train/case30/case30_day0/s...  small_bowel   \n",
       "33909  /home/ares/work/TIS/train/case30/case30_day0/s...  large_bowel   \n",
       "33910  /home/ares/work/TIS/train/case30/case30_day0/s...  small_bowel   \n",
       "33911  /home/ares/work/TIS/train/case30/case30_day0/s...  large_bowel   \n",
       "33912  /home/ares/work/TIS/train/case30/case30_day0/s...  small_bowel   \n",
       "\n",
       "                                            segmentation  \n",
       "0      28094 3 28358 7 28623 9 28889 9 29155 9 29421 ...  \n",
       "1      27561 8 27825 11 28090 13 28355 14 28620 15 28...  \n",
       "2      15323 4 15587 8 15852 10 16117 11 16383 12 166...  \n",
       "3      14792 5 15056 9 15321 11 15587 11 15852 13 161...  \n",
       "4      14526 6 14789 12 15054 14 15319 16 15584 17 15...  \n",
       "...                                                  ...  \n",
       "33908  22540 1 22804 5 23069 7 23334 10 23600 11 2386...  \n",
       "33909  18746 7 19009 23 19038 7 19273 44 19537 49 198...  \n",
       "33910  23079 1 23343 6 23608 9 23874 11 24139 13 2440...  \n",
       "33911  18746 2 19010 8 19040 3 19274 25 19302 12 1953...  \n",
       "33912  21457 6 21722 10 21987 15 22252 18 22517 21 22...  \n",
       "\n",
       "[33913 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refreshed_data = data.copy()\n",
    "refreshed_data['id'] = all_paths_to_imgs\n",
    "refreshed_data.index = range(refreshed_data.shape[0])\n",
    "refreshed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "173079ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for data visualization\n",
    "def visualize(**images):\n",
    "    \"\"\"PLot images in one row.\"\"\"\n",
    "    n = len(images)\n",
    "    plt.figure(figsize=(16, 5))\n",
    "    for i, (name, image) in enumerate(images.items()):\n",
    "        plt.subplot(1, n, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(' '.join(name.split('_')).title())\n",
    "        plt.imshow(image)\n",
    "    plt.show()\n",
    "    \n",
    "# helper function for data visualization    \n",
    "def denormalize(x):\n",
    "    \"\"\"Scale image to range 0..1 for correct plot\"\"\"\n",
    "    x_max = np.percentile(x, 98)\n",
    "    x_min = np.percentile(x, 2)    \n",
    "    x = (x - x_min) / (x_max - x_min)\n",
    "    x = x.clip(0, 1)\n",
    "    return x\n",
    "\n",
    "\n",
    "# classes for data loading and preprocessing\n",
    "class Dataset:\n",
    "    \"\"\"CamVid Dataset. Read images, apply augmentation and preprocessing transformations.\n",
    "    \n",
    "    Args:\n",
    "        images_dir (str): path to images folder\n",
    "        masks_dir (str): path to segmentation masks folder\n",
    "        class_values (list): values of classes to extract from segmentation mask\n",
    "        augmentation (albumentations.Compose): data transfromation pipeline \n",
    "            (e.g. flip, scale, etc.)\n",
    "        preprocessing (albumentations.Compose): data preprocessing \n",
    "            (e.g. noralization, shape manipulation, etc.)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "            self,\n",
    "            data: pd.DataFrame,\n",
    "            augmentation=None,\n",
    "            preprocessing=None,\n",
    "    ):\n",
    "        self.images_fps = data['id'].values\n",
    "        self.masks_rle_encode = data['segmentation'].values\n",
    "\n",
    "        # convert str names to class values on masks\n",
    "        \n",
    "        self.augmentation = augmentation\n",
    "        self.preprocessing = preprocessing\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        \n",
    "        # read data\n",
    "        image = cv2.imread(self.images_fps[i])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.uint8)\n",
    "\n",
    "        mask = rle_decode(self.masks_rle_encode[i], image.shape[:2]).astype(np.float32)\n",
    "        mask = np.expand_dims(mask, axis=2)\n",
    "        \n",
    "        # add background if mask is not binary\n",
    "        # if mask.shape[-1] != 1:\n",
    "        #     background = 1 - mask.sum(axis=-1, keepdims=True)\n",
    "        #     mask = np.concatenate((mask, background), axis=-1)\n",
    "        \n",
    "        \n",
    "        # apply augmentations\n",
    "        if self.augmentation:\n",
    "            sample = self.augmentation(image=image, mask=mask)\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "        \n",
    "        # apply preprocessing\n",
    "        if self.preprocessing:\n",
    "            sample = self.preprocessing(image=image, mask=mask)\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "            \n",
    "        return image, mask\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.images_fps.shape[0]\n",
    "    \n",
    "    \n",
    "class Dataloader(tf.keras.utils.Sequence):\n",
    "    \"\"\"Load data from dataset and form batches\n",
    "    \n",
    "    Args:\n",
    "        dataset: instance of Dataset class for image loading and preprocessing.\n",
    "        batch_size: Integet number of images in batch.\n",
    "        shuffle: Boolean, if `True` shuffle image indexes each epoch.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, dataset, batch_size=1, shuffle=False):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indexes = np.arange(len(self.dataset))\n",
    "\n",
    "        self.on_epoch_end()\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        \n",
    "        # collect batch data\n",
    "        start = i * self.batch_size\n",
    "        stop = (i + 1) * self.batch_size\n",
    "        data = []\n",
    "        for j in range(start, stop):\n",
    "            data.append(self.dataset[j])\n",
    "        # transpose list of lists\n",
    "        batch = [np.stack(samples, axis=0) for samples in zip(*data)]\n",
    "        \n",
    "        return batch\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"Denotes the number of batches per epoch\"\"\"\n",
    "        return len(self.indexes) // self.batch_size\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"Callback function to shuffle indexes each epoch\"\"\"\n",
    "        if self.shuffle:\n",
    "            self.indexes = np.random.permutation(self.indexes)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a17967f",
   "metadata": {},
   "source": [
    "## CREATE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7744e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "BACKBONE = 'efficientnetb0'\n",
    "BATCH_SIZE = 5\n",
    "LR = 0.01\n",
    "EPOCHS = 100\n",
    "MODEL_NAME = \"unet\"\n",
    "PATH_TO_MODEL = f\"./models/{MODEL_NAME}.h5\"\n",
    "LOAD_MODEL = True\n",
    "\n",
    "base_model_params = {\n",
    "    \"backbone\": BACKBONE,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"epochs\": EPOCHS\n",
    "}\n",
    "preprocess_input = sm.get_preprocessing(BACKBONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ada1b8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col_name = \"class\"\n",
    "train_data, val_data, y_train, y_val = train_test_split(refreshed_data.drop(target_col_name, axis=1), refreshed_data[target_col_name], \\\n",
    "    test_size=0.2, stratify=refreshed_data[target_col_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35a1919d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(\n",
    "    data=train_data.join(y_train), \n",
    "    augmentation=get_training_augmentation(),\n",
    "    preprocessing=get_preprocessing(preprocess_input))\n",
    "\n",
    "val_dataset = Dataset(\n",
    "    val_data.join(y_val),\n",
    "    augmentation=get_validation_augmentation(),\n",
    "    preprocessing=get_preprocessing(preprocess_input)\n",
    "    )\n",
    "\n",
    "train_data_loader = Dataloader(train_dataset, batch_size=BATCH_SIZE)\n",
    "val_data_loader = Dataloader(val_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d18dc2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-29 11:47:11.458720: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-29 11:47:11.459064: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-29 11:47:11.459314: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-29 11:47:11.459900: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-29 11:47:11.460164: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-29 11:47:11.460410: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-29 11:47:11.460702: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-29 11:47:11.460956: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-29 11:47:11.461181: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2642 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-29 11:47:12.834786: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 17989632 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "# define network parameters\n",
    "n_classes = 3  # case for binary and multiclass segmentation\n",
    "activation = 'sigmoid' if n_classes == 1 else 'softmax'\n",
    "\n",
    "#create model\n",
    "model = sm.Unet(BACKBONE, classes=n_classes, activation=activation)\n",
    "MODEL_NAME = \"Unet\"\n",
    "# model = sm.FPN(BACKBONE, classes=n_classes, activation=activation)\n",
    "\n",
    "if LOAD_MODEL:\n",
    "    model.load_weights(PATH_TO_MODEL)\n",
    "    print('weights loaded')\n",
    "    base_model_params['model-name'] = MODEL_NAME\n",
    "    base_model_params['backbone-name'] = BACKBONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5195235e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define optomizer\n",
    "\n",
    "optim = tf.keras.optimizers.Adam(LR)\n",
    "base_model_params['optimizer'] = optim.get_config()['name']\n",
    "\n",
    "# Segmentation models losses can be combined together by '+' and scaled by integer or float factor\n",
    "dice_coef, focal_coef = 0.6, 0.4\n",
    "dice_loss = sm.losses.DiceLoss()\n",
    "focal_loss = sm.losses.BinaryFocalLoss() if n_classes == 1 else sm.losses.CategoricalFocalLoss()\n",
    "total_loss = dice_loss*dice_coef + (1 * focal_loss)*focal_coef\n",
    "\n",
    "base_model_params['dice loss coef'] = dice_coef\n",
    "base_model_params['focal loss coef'] = focal_coef\n",
    "\n",
    "# actulally total_loss can be imported directly from library, above example just show you how to manipulate with losses\n",
    "# total_loss = sm.losses.binary_focal_dice_loss # or sm.losses.categorical_focal_dice_loss \n",
    "\n",
    "metrics = [sm.metrics.IOUScore(threshold=0.5), sm.metrics.FScore(threshold=0.5)]\n",
    "\n",
    "# learning rate schedule\n",
    "def step_decay(epoch):\n",
    "\tinitial_lrate = 0.001\n",
    "\tdrop = 0.9\n",
    "\tepochs_drop = 10.0\n",
    "\tlrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "\treturn lrate\n",
    "\n",
    "# compile keras model with defined optimozer, loss and metrics\n",
    "model.compile(optim, total_loss, metrics)\n",
    "\n",
    "callbacks = [\n",
    "\ttf.keras.callbacks.ModelCheckpoint(PATH_TO_MODEL, save_weights_only=True, save_best_only=True, mode='min'),\n",
    "\ttf.keras.callbacks.CSVLogger('./logging/log.csv'),\n",
    "\ttf.keras.callbacks.LearningRateScheduler(step_decay)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0599d6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-29 11:47:44.361758: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8400\n",
      "2022-09-29 11:47:47.061736: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.08GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-09-29 11:47:47.062486: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.08GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-09-29 11:47:47.231953: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.09GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-09-29 11:47:47.231988: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.09GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-09-29 11:47:47.456453: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.34GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-09-29 11:47:47.456487: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.34GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-09-29 11:47:47.702937: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.93GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-09-29 11:47:47.702974: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.93GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-09-29 11:47:49.226899: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.61GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-09-29 11:47:49.226934: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.61GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5426/5426 [==============================] - 1846s 338ms/step - loss: 0.4814 - iou_score: 0.1282 - f1-score: 0.2085 - val_loss: 0.4672 - val_iou_score: 0.1436 - val_f1-score: 0.2275 - lr: 0.0010\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-29 12:18:23.297255: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 17989632 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5426/5426 [==============================] - 1712s 316ms/step - loss: 0.4807 - iou_score: 0.1290 - f1-score: 0.2096 - val_loss: 0.4679 - val_iou_score: 0.1423 - val_f1-score: 0.2272 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "5426/5426 [==============================] - 1712s 315ms/step - loss: 0.4804 - iou_score: 0.1293 - f1-score: 0.2100 - val_loss: 0.4693 - val_iou_score: 0.1407 - val_f1-score: 0.2247 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "5426/5426 [==============================] - 1711s 315ms/step - loss: 0.4799 - iou_score: 0.1298 - f1-score: 0.2107 - val_loss: 0.4718 - val_iou_score: 0.1387 - val_f1-score: 0.2203 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "5426/5426 [==============================] - 1712s 315ms/step - loss: 0.4793 - iou_score: 0.1305 - f1-score: 0.2117 - val_loss: 0.4648 - val_iou_score: 0.1454 - val_f1-score: 0.2309 - lr: 0.0010\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-29 14:12:30.291203: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 17989632 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5426/5426 [==============================] - 1710s 315ms/step - loss: 0.4795 - iou_score: 0.1303 - f1-score: 0.2113 - val_loss: 0.4673 - val_iou_score: 0.1431 - val_f1-score: 0.2280 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "5426/5426 [==============================] - 1709s 315ms/step - loss: 0.4789 - iou_score: 0.1311 - f1-score: 0.2124 - val_loss: 0.4676 - val_iou_score: 0.1434 - val_f1-score: 0.2276 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "5426/5426 [==============================] - 1708s 315ms/step - loss: 0.4783 - iou_score: 0.1316 - f1-score: 0.2131 - val_loss: 0.4732 - val_iou_score: 0.1374 - val_f1-score: 0.2184 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "4456/5426 [=======================>......] - ETA: 9:21 - loss: 0.4788 - iou_score: 0.1312 - f1-score: 0.2125"
     ]
    }
   ],
   "source": [
    "# # train model\n",
    "history = model.fit_generator(\n",
    "    train_data_loader,\n",
    "    steps_per_epoch=len(train_data_loader),\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=val_data_loader,\n",
    "    validation_steps=len(val_data_loader),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21ba7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_params['loss'] = history.history['loss']\n",
    "with mlflow.start_run():\n",
    "    # mlflow.create_experiment('fit-segmentation-model', artifact_location='./models')\n",
    "    mlflow.log_params(base_model_params)\n",
    "    mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc6275fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from  mlflow.tracking import MlflowClient\n",
    "client = MlflowClient()\n",
    "experiments = client.list_experiments() # returns a list of mlflow.entities.Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6af9ad5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///home/ares/work/TIS/mlruns/0', experiment_id='0', lifecycle_stage='active', name='Default', tags={}>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiments[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac3ef5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = client.get_run('0207c13cc40a4c2e99fa251bd6166f82')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d910ca17",
   "metadata": {},
   "source": [
    "## Famous models preporation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e78ed3",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
